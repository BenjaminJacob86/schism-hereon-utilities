import sys
import os
""" Code to expand schism downscaling for child model boundaries that liew within dry follaing areay of mother model
so that the schism interpolate_vraibale utilities where used with limitted boudanry.
In mother dry areay child model takes over vertical mean T and S values of nn profiles in mothder model both if wet and and dry
the simulated elevation if wet and sea level 0 if dry. For uv the vertical mean of nn profile if wet and zero if dry
 """

sys.path.insert(0,'/home/g/g260114/schism-hzg-utilities/')
from schism import* # import schism class to read grid structure
import glob
# gen forcing using nudign scripts for reduced boundary
# overwrite neareas neighbour for missing boundaries


# schout style:
ncdir='/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/forcingFromSNS/'
schismfiles=[] 
for iorder in range(8): # check for schout_nc files until 99999
	schismfiles+=glob.glob(ncdir+'schout_'+'?'*iorder+'.nc')
nrs=[int(file[file.rfind('_')+1:file.index('.nc')]) for file in schismfiles]
schismfiles=list(np.asarray(schismfiles)[np.argsort(nrs)])
nrs=list(np.asarray(nrs)[np.argsort(nrs)])

rundir0='/work/gg0028/g260094/SNS/SNSE2D_MSLRnsob_prc50_r212/'


s0dir='/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/forcingFromSNS/' # mother grid
#s1dir='/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/'                    # desitiantion grid reduced bd
#s2dir='/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/'					   # destination grid full bd
s1orgdir='/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/'

os.chdir(s1orgdir)
s1org=schism_setup()
os.chdir(s0dir)
s0=schism_setup(hgrid_file='bg.gr3')
#os.chdir(s1dir)
s1=schism_setup(hgrid_file='fg.gr3')

nvertmax=21 #max number of vertical layers in destination grid

#acc=schism_output2('/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/forcingFromSNS/sub').nc # to much space
os.chdir('/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/forcingFromSNS/')

p=param('/work/gg0028/g260114/RUNS/GermanBight/GB_2017_wave_sed/ClimateProj/forcingFromSNS//param.nml')

openbd_segs=[0,] # open boundary to apply forcing for


# get dates
p=param(rundir0+'/param.nml')
reftime=dt.datetime(int(p.get_parameter('start_year')),
int(p.get_parameter('start_month')),
int(p.get_parameter('start_day')),
int(p.get_parameter('start_hour')),0,0)		


#startime for period
starttime=dt.datetime(2090,1,1,0,0)
endtime=dt.datetime(2091,1,1,0,0)
#endtime for period



# determine gaps in boundary to be filled with nn interpolation
appendbds=np.asarray([ibd-1 for ibd in s1org.bdy_segments[0] if ibd not in s1.bdy_segments[0]])
appendbds_indx=[ibd-1 for ibd in s1org.bdy_segments[0] if ibd not in s1.bdy_segments[0]]
s0.init_node_tree(latlon=False)
xbd=np.asarray(s1.x)[appendbds]
ybd=np.asarray(s1.y)[appendbds]
bdcoords=list(zip(xbd,ybd))
nnpoints=s0.node_tree_xy.query(bdcoords)[1]

insert_index=[np.where(s1org.bdy_segments[0]==ibd+1)[0][0] for ibd in appendbds]

# set frcbd
if len(openbd_segs)>0:
	frcbdnodes=[]
	for seg in openbd_segs:
		frcbdnodes+=s1org.bdy_segments[seg]
		bdyvgrid = np.asarray([s1org.vgrid[ii].filled(-1.) for ii in frcbdnodes ])
else:
	frcbdnodes=s1org.bdy_nodes




# find nearest element centers for dry assessment
# element centers
x0,y0=np.asarray(s0.x),np.asarray(s0.y)
cx=np.mean(x0[s0.nvplt],axis=1)
cy=np.mean(y0[s0.nvplt],axis=1)
elcoords=[[cx[i],cy[i]] for i in range(len(cx))] # pooint pairs of nodes
elem_nn_tree = cKDTree(elcoords) # next neighbour search tree	     


# search defect stacks
#nts=np.asarray([len(xr.open_dataset(file).time) for file in schismfiles])

#nts=np.zeros(len(schismfiles))
#for i,file in enumerate(schismfiles):
#	nts[i]=len(xr.open_dataset(file).time)



# load th.nc generated by interpolat_variables
dsin=xr.open_dataset('elev2D.th.nc')
elevin=dsin['time_series'].values
timein=dsin['time'].values
dsin=xr.open_dataset('SAL_3D.th.nc')
saltin=dsin['time_series'].values
dsin=xr.open_dataset('TEM_3D.th.nc')
tempin=dsin['time_series'].values
dsin=xr.open_dataset('uv3D.th.nc')
uvin=dsin['time_series'].values

# limit indices to wanted  period
seconds_min=(starttime-reftime)/dt.timedelta(seconds=1)
seconds_max=(endtime-reftime)/dt.timedelta(seconds=1)
imin=np.where(timein>=seconds_min)[0][0]
imax=np.where(timein>=seconds_max)[0][0]
nt2=imax-imin


# find missing nodes
# fill intersecting
#isect,ainb,bina=np.intersect1d(np.asarray(s1.bdy_segments[0]),np.asarray(s1org.bdy_segments[0]),return_indices=True)
isect,ainb,bina=np.intersect1d(np.asarray(s1.bdy_segments[0][1:]),np.asarray(s1org.bdy_segments[0]),return_indices=True) #temporary test
np.asarray(s1.bdy_segments[0])[ainb]==np.asarray(s1org.bdy_segments[0])[bina]


buffer=1 # add buffer to account for th.nc starting at zero and foricng output from schism starting at dt#
		 # 1 extrara dt is needed will be reomved afterwards (this si considering hourly forcing of th.nc in an schism outtputs to be integrater into this)
nz=dsin.time_series.shape[2]
elev=np.zeros((nt2+buffer,len(s1org.bdy_segments[0]),1,1))
T=np.zeros((nt2+buffer,len(s1org.bdy_segments[0]),nz,1))
S=np.zeros((nt2+buffer,len(s1org.bdy_segments[0]),nz,1))
uv=np.zeros((nt2+buffer,len(s1org.bdy_segments[0]),nz,2))

# overtake alreay present data
#elev[:,ainb,:]=elevin[:nt2,ainb,:]
#S[:,ainb,:]=saltin[:nt2,ainb,:]
#T[:,ainb,:]=tempin[:nt2,ainb,:]
#uv[:,ainb,:]=uvin[:nt2,ainb,:]


#offset by one hour iguess
elev[:-buffer,ainb,:]=elevin[imin:imax,ainb,:]
S[:-buffer,ainb,:]=saltin[imin:imax,ainb,:]
T[:-buffer,ainb,:]=tempin[imin:imax,ainb,:]
uv[:-buffer,ainb,:]=uvin[imin:imax,ainb,:]

print(T.shape)
D=np.asarray(s1.depths) # depths in destination grid


igridnode=np.asarray(s1org.bdy_segments[0])[insert_index]-1 # grid nodes to be filled
nn_element=elem_nn_tree.query(list(zip(xbd,ybd)))[1] #nearest element to subset of boundarypoints that can potetnielly fall dry
check_elem=s0.nvplt2nvp[nn_element] # original element indices with respect to non splitted grid

#D[igridnode]	
#drydepth= 
  #set water level to this value if parent model is dry at open bd
file=schismfiles[0]
ds=xr.open_dataset(file)
nt_stack=len(ds.time)
Dstack=np.tile(D[igridnode],(nt_stack,1))

insert_index=np.asarray(insert_index)
insert_logic=np.zeros(elev.shape[1],bool)
insert_logic[insert_index]=True
insert_index_stack=np.tile(insert_index,(nt_stack,1))


# subset days

#sub select files needed for date range
file0=schismfiles[0]

dsi=xr.open_dataset(file0)

dts=(dsi.time[1]-dsi.time[0]).values/np.timedelta64(1,'s')
seconds_per_stack=(dsi.time[-1]-dsi.time[0]).values/np.timedelta64(1,'s')+dts

stack_min=int(np.ceil(seconds_min/seconds_per_stack))
stack_max=int(np.ceil(seconds_max/seconds_per_stack))

#schismfiles=schismfiles[:10]
for i,file in enumerate(schismfiles[stack_min:stack_max]):
	tinds=i*nt_stack+np.arange(nt_stack)+1  # needs to be checked

	if tinds[-1]<nt2+1:
		print(file)
		ds=xr.open_dataset(file)
		
		#timein2=ds.time.values
		#seconds2=(timein2-np.asarray(reftime,np.datetime64))/np.timedelta64(1,'s')
		#seconds2-timein[:len(seconds2)]
		
		dsnn=ds.sel(nSCHISM_hgrid_node=nnpoints)	
		delnn=ds.sel(nSCHISM_hgrid_face=check_elem)	
		isdry=np.asarray(delnn.wetdry_elem.values,bool)
		iswet=~isdry

		# user values from nearest model points
		elevvals=dsnn['elev'].values
		Tvals=dsnn['temp'].values
		Svals=dsnn['salt'].values
		uvvals=dsnn['hvel'].values
		# for T and S use the remaining stored values (need to correct if dummy)
		#tmean=Tvals.mean(axis=2)
		#smean=Svals.mean(axis=2)
		#uvmeanp.nanmean(n=uvvals.mean(axis=2)
		tmean=np.nanmean(Tvals,axis=2)
		smean=np.nanmean(Svals,axis=2)
		uvmean=np.nanmean(uvvals,axis=2)
		
		# sub indexing not working?
		#for iz in range(nvertmax):
		#	T[tinds,:][:,insert_index,iz,0]=tmean # mean value from two layers
		#	S[tinds,:][:,insert_index,iz,0]=smean # mean value from two layers
		#	uv[tinds,:][:,insert_index,iz,0][iswet]=uvmean[:,:,0][iswet] #take wet value	
		#	uv[tinds,:][:,insert_index,iz,1][iswet]=uvmean[:,:,1][iswet]
		#elev[tinds,:][:,insert_index,0,0][iswet]=elevvals[iswet] # leave sea level at zero

		
		# generate a vecotrindex repliacating the 3 level subset	
		#i2,j2=np.meshgrid(tinds,insert_index)				
		j2all,i2all=np.meshgrid(insert_index,tinds)				
		i2,j2=i2all[iswet],j2all[iswet] # only at wet grid points
		
		for iz in range(nvertmax):
			T[i2all,j2all,iz,0]=tmean # mean value from two layers
			S[i2all,j2all,iz,0]=smean # mean value from two layers
			uv[i2,j2,iz,0]=uvmean[:,:,0][iswet] #take wet value	
			uv[i2,j2,iz,1]=uvmean[:,:,1][iswet]
		elev[i2,j2,0,0]=elevvals[iswet] # leave sea level at zero
	else:
		break
#cdo -O merge $outDir/${outname/cur/???} $outDir/${outname/_cur/}
#
#
#
#i2,j2=np.meshgrid(tinds,insert_index)		
#elev[i2,j2,:]=1
#
#
#
#		
#elev[tinds,:][:,insert_index,0,0][iswet]		
#
#
# # Assign values to the output arrays
#T[tinds, :, :, 0] = np.repeat(tmean[:, :, np.newaxis], nvertmax, axis=2)
#S[tinds, :, :, 0] = np.repeat(smean[:, :, np.newaxis], nvertmax, axis=2)
#uv[tinds, :, :, 0][iswet] = np.repeat(uvmean[:, :, 0][:, :, np.newaxis], nvertmax, axis=2)[iswet]
#uv[tinds, :, :, 1][iswet] = np.repeat(uvmean[:, :, 1][:, :, np.newaxis], nvertmax, axis=2)[iswet]
#elev[tinds, :, 0, 0][iswet] = elevvals[iswet]
#
#
#
#		
#elev[tinds,:][:,insert_index,0,0]		
#		
#elev[tinds,insert_logic,0,0][iswet]
		
time=dsin['time'].values[:nt2+1]	
ilast=tinds[-1]+1-buffer
time=time[:ilast]
elev=elev[:ilast,:]
S=S[:ilast,:]
T=T[:ilast,:]
uv=uv[:ilast,:]

elev=elev[:ilast,:]
S=S[:ilast,:]
T=T[:ilast,:]
uv=uv[:ilast,:]


replace=S[0,:]==0

#elev[0,replace[:,0,0],:]=elev[1,replace[:,0,0],:]
#S[0,replace,:]=S[1,replace,:]
#T[0,replace,:]=T[1,replace,:]
#uv[0,replace,:]=uv[1,replace,:]

#elev[0,replace[:,0,0],:]=elev[1,replace[:,0,0],:]
#S[0,replace,:]=S[1,replace,:]
#T[0,replace,:]=T[1,replace,:]
#uv[0,replace,:]=uv[1,replace,:]

#first step could be unenitialized just ued 2nd
elev[0,:]=elev[1,:]
S[0,:]=S[1,:]
T[0,:]=T[1,:]
uv[0,:]=uv[1,:]


start_date=np.asarray(reftime,np.datetime64)+np.timedelta64(1,'s')*timein[imin]
end_date=np.asarray(reftime,np.datetime64)+np.timedelta64(1,'s')*timein[imax]

timetag=str(start_date)[:19].replace('-','')+'-'+str(end_date)[:19].replace('-','')

s1org.write_bdy_netcdf('elev_2D_expand'+timetag+'.th.nc',time,elev,frcbdnodes=frcbdnodes)
s1org.write_bdy_netcdf('SAL_3D_expand'+timetag+'.th.nc',time,S,frcbdnodes=frcbdnodes)
s1org.write_bdy_netcdf('TEM_3D_expand'+timetag+'.th.nc',time,T,frcbdnodes=frcbdnodes)
s1org.write_bdy_netcdf('uv3D_expand'+timetag+'.th.nc',time,uv,frcbdnodes=frcbdnodes)



